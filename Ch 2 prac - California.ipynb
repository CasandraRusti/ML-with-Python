{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports for all practice\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# mlpscaler = StandardScaler()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "#a= time.time()\n",
    "#b= time.time()\n",
    "#print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (20640, 8)\n",
      "Scaled Data shape: (20640, 8)\n",
      "per-feature minimum before scaling:\n",
      " [   0.4999        1.            0.84615385    0.33333333    3.\n",
      "    0.69230769   32.54       -124.35      ]\n",
      "per-feature maximum before scaling:\n",
      " [ 1.50001000e+01  5.20000000e+01  1.41909091e+02  3.40666667e+01\n",
      "  3.56820000e+04  1.24333333e+03  4.19200000e+01 -1.14310000e+02]\n",
      "per-feature minimum after scaling:\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "per-feature maximum after scaling:\n",
      " [1.        1.        1.        1.        1.        1.        0.9968119\n",
      " 1.       ]\n"
     ]
    }
   ],
   "source": [
    "# Import and split the data\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "cali = fetch_california_housing()\n",
    "print(\"Data shape: {}\".format(california.data.shape))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cali.data, cali.target, random_state=69)\n",
    "\n",
    "\n",
    "## SCALE & split scaled data\n",
    "scaler.fit(cali.data)\n",
    "X_scaled = scaler.transform(cali.data)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(\n",
    "    X_scaled, cali.target, random_state=69)\n",
    "print(\"Scaled Data shape: {}\".format(X_scaled.shape))\n",
    "\n",
    "print(\"per-feature minimum before scaling:\\n {}\".format(X_train.min(axis=0)))\n",
    "print(\"per-feature maximum before scaling:\\n {}\".format(X_train.max(axis=0)))\n",
    "print(\"per-feature minimum after scaling:\\n {}\".format(\n",
    "X_train_scaled.min(axis=0)))\n",
    "print(\"per-feature maximum after scaling:\\n {}\".format(\n",
    "X_train_scaled.max(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.6052\n",
      "Test set score: 0.6090\n",
      "Run time: 0.0237\n"
     ]
    }
   ],
   "source": [
    "## ROW 25\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# DEFAULT parameters: Ridge Regression\n",
    "ridge=Ridge().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.4f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(ridge.score(X_test, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.6048\n",
      "Test set score: 0.6094\n",
      "Run time: 0.0160\n"
     ]
    }
   ],
   "source": [
    "## ROW 26\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# CUSTOM parameters: Ridge Regression\n",
    "ridge=Ridge(alpha=100).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.4f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(ridge.score(X_test, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.9726\n",
      "Test set score: 0.8083\n",
      "Run time: 10.9911\n"
     ]
    }
   ],
   "source": [
    "## ROW 27\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# DEFAULT parameters: Random Forest REGRESSOR\n",
    "forest = RandomForestRegressor(random_state=69).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.4f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(forest.score(X_test, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9734\n",
      "Test set score: 0.8092\n",
      "Run time: 21.6393\n"
     ]
    }
   ],
   "source": [
    "## ROW 28\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# CUSTOM parameters: Random Forest REGRESSOR\n",
    "forest_cust = RandomForestRegressor(n_estimators=200, random_state=69).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.4f}\".format(forest_cust.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(forest_cust.score(X_test, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.8052\n",
      "Test set score: 0.7782\n",
      "Run time: 3.2462\n"
     ]
    }
   ],
   "source": [
    "## ROW 29\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# DEFAULT parameters: Gradient Boosting REGRESSOR\n",
    "gbrt = GradientBoostingRegressor(random_state=69).fit(X_train, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(gbrt.score(X_test, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.8622\n",
      "Test set score: 0.8154\n",
      "Run time: 3.2315\n"
     ]
    }
   ],
   "source": [
    "## ROW 30 - learning rate\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# CUSTOM parameters: Gradient Boosting REGRESSOR\n",
    "## parameters to play with are learning_rate OR max_depth\n",
    "## tried a few LRs, .4 and .5 both give .815\n",
    "gbrt_cust1 = GradientBoostingRegressor(learning_rate=0.4,random_state=69).fit(X_train, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(gbrt_cust1.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(gbrt_cust1.score(X_test, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.9744\n",
      "Test set score: 0.8322\n",
      "Run time: 9.2577\n"
     ]
    }
   ],
   "source": [
    "## ROW 30 - max depth\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# CUSTOM parameters: Gradient Boosting REGRESSOR\n",
    "## parameters to play with are learning_rate OR max_depth\n",
    "## depth 8 = 0.8316\n",
    "## depth 9 = 0.8322\n",
    "## depth 10 = 0.8287, 11=0.8209, 15+ reduces accuracy significantly)\n",
    "gbrt_cust2 = GradientBoostingRegressor(max_depth=9,random_state=69).fit(X_train, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(gbrt_cust2.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(gbrt_cust2.score(X_test, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.6575\n",
      "Test set score: 0.6614\n",
      "Run time: 14.2079\n"
     ]
    }
   ],
   "source": [
    "## ROW 31\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# DEFAULT parameters: SVM\n",
    "svr = SVR().fit(X_train_scaled, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(svr.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(svr.score(X_test_scaled, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.6862\n",
      "Test set score: 0.6713\n",
      "Run time: 15.1534\n"
     ]
    }
   ],
   "source": [
    "## ROW 32\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# CUSTOM parameters: SVM\n",
    "svr_cust = SVR(C=10).fit(X_train_scaled, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(svr_cust.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(svr_cust.score(X_test_scaled, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))\n",
    "\n",
    "## C=1000, Trainng set score: 0.7424, Test set score: -0.1790, Run time: 179.9564\n",
    "## C=400, Trainng set score: 0.7320, Test set score: 0.0581, Run time: 82.2556\n",
    "## C=100, Trainng set score: 0.7158, Test set score: 0.4063, Run time: 31.3714\n",
    "## C=50, Trainng set score: 0.7087, Test set score: 0.5530, Run time: 22.2034\n",
    "## C=25, Trainng set score: 0.6991, Test set score: 0.6353, Run time: 17.9048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.7606\n",
      "Test set score: 0.7510\n",
      "Run time: 106.1220\n"
     ]
    }
   ],
   "source": [
    "## ROW 33\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# DEFAULT parameters: Neural Networks\n",
    "mlp = MLPRegressor(max_iter=1000000000,random_state=69).fit(X_train_scaled, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-5c1bb9771175>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m## tried hidden_layer_sizes= ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m## tried alpha of ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmlp_cust\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m69\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trainng set score: {:.4f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp_cust\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test set score: {:.4f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlp_cust\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    625\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m         \"\"\"\n\u001b[1;32m--> 627\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_STOCHASTIC_SOLVERS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m             self._fit_stochastic(X, y, activations, deltas, coef_grads,\n\u001b[1;32m--> 370\u001b[1;33m                                  intercept_grads, layer_units, incremental)\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;31m# Run the LBFGS solver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_stochastic\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units, incremental)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    514\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "## ROW 34\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# CUSTOM parameters: Neural Networks\n",
    "## tried hidden_layer_sizes= ...\n",
    "## tried alpha of ...\n",
    "mlp_cust = MLPRegressor(alpha=.01,max_iter=1e9,hidden_layer_sizes=[10, 10],random_state=69).fit(X_train_scaled, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(mlp_cust.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(mlp_cust.score(X_test_scaled, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))\n",
    "\n",
    "## alpha=0.5,hidden_layer_sizes=[25, 25], Trainng set score: 0.6384, Test set score: 0.6471, Run time: 5.6398\n",
    "## alpha=0.5,hidden_layer_sizes=[10, 10], Trainng set score: 0.6427, Test set score: 0.6500, Run time: 8.1963"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
