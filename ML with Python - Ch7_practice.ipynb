{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 474.0226\n"
     ]
    }
   ],
   "source": [
    "## if you put the full file path, no matter what active folder you're in it will work\n",
    "\n",
    "import time\n",
    "a= time.time()\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files(\"aclImdb/train\")\n",
    "# load_files returns a bunch, containing training texts and training labels\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-3-a0e19403c5a1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-a0e19403c5a1>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    with open ('/tmp/input.txt','r') as f:\u001b[0m\n\u001b[1;37m                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "with open ('/tmp/input.txt','r') as f:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier non trouvé\n"
     ]
    }
   ],
   "source": [
    "print(\"Fichier non trouvé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/records.log'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3576eb56f66c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrépertoire\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/tmp/records.log\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrépertoire\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/records.log'"
     ]
    }
   ],
   "source": [
    "répertoire = \"/tmp/records.log\"\n",
    "with open(répertoire, \"w\") as f:\n",
    "    f.write(\"test\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57344"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> chr(57344)\n",
    "'\\ue000'\n",
    ">>> ord('\\ue000')\n",
    "57344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pg 334 - find '007' references\n",
    "\n",
    "# Pseudo code in Matlab \n",
    "\n",
    "##true false column vector\n",
    "# doesn't work since it can be >= 0 X_train(:,9) == 1\n",
    "any(X_train(:,10))\n",
    "#OR\n",
    "X_train(:,10) > 0\n",
    "\n",
    "temp = 1:size(X_train,1)\n",
    "temp(X_train(:,10) == 1) \n",
    "temp = temp(X_train(:,10) == 1)\n",
    "text_train(temp(1))\n",
    "    \n",
    "print(\"text_train[6]:\\n{}\".format(text_train[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pg 338 - creating stop words that appear a lot\n",
    "\n",
    "## sum accross the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 0.0000 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "a= time.time()\n",
    "\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f} min\".format((b-a)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MyTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, first_parameter=1, second_parameter=2):\n",
    "        # All parameters must be specified in the __init__ function\n",
    "        self.first_parameter = 1\n",
    "        self.second_parameter = 2\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # fit should only take X and y as parameters\n",
    "        # Even if your model is unsupervised, you need to accept a y argument!\n",
    "        # Model fitting code goes here\n",
    "        print(\"fitting the model right here\")\n",
    "        # fit returns self\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # transform takes as parameter only X\n",
    "        # Apply some transformation to X\n",
    "        X_transformed = X + 1\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-6673fe857c80>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-6673fe857c80>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    conda install -c conda-forge spacy\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "a= time.time()\n",
    "\n",
    "conda install -c conda-forge spacy\n",
    "conda install -c conda-forge spacy-lookups-data\n",
    "python -m spacy download en_core_web_sm\n",
    "python -m spacy download ro_core_news_sm\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f} min\".format((b-a)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DON'T RUN##\n",
    "#### OUTPUT WHEN INTERUPTED! \n",
    "\n",
    "## In-32, pg 343\n",
    "\n",
    "## changed solver to match book version default and added max_iter\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "pipe = make_pipeline(TfidfVectorizer(min_df=5), LogisticRegression(solver='liblinear', max_iter=1000))\n",
    "# running the grid search takes a long time because of the\n",
    "# relatively large grid and the inclusion of trigrams\n",
    "param_grid = {\"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              \"tfidfvectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(text_train, y_train)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid.best_params_))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f} min\".format((b-a)/60))\n",
    "\n",
    "#### OUTPUT\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "KeyboardInterrupt                         Traceback (most recent call last)\n",
    "<ipython-input-34-a6380bab4b69> in <module>\n",
    "     12 \n",
    "     13 grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "---> 14 grid.fit(text_train, y_train)\n",
    "     15 print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "     16 print(\"Best parameters:\\n{}\".format(grid.best_params_))\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self, X, y, groups, **fit_params)\n",
    "    708                 return results\n",
    "    709 \n",
    "--> 710             self._run_search(evaluate_candidates)\n",
    "    711 \n",
    "    712         # For multi-metric evaluation, store the best_index_, best_params_ and\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in _run_search(self, evaluate_candidates)\n",
    "   1149     def _run_search(self, evaluate_candidates):\n",
    "   1150         \"\"\"Search all candidates in param_grid\"\"\"\n",
    "-> 1151         evaluate_candidates(ParameterGrid(self.param_grid))\n",
    "   1152 \n",
    "   1153 \n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in evaluate_candidates(candidate_params)\n",
    "    687                                for parameters, (train, test)\n",
    "    688                                in product(candidate_params,\n",
    "--> 689                                           cv.split(X, y, groups)))\n",
    "    690 \n",
    "    691                 if len(out) < 1:\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py in __call__(self, iterable)\n",
    "   1005                 self._iterating = self._original_iterator is not None\n",
    "   1006 \n",
    "-> 1007             while self.dispatch_one_batch(iterator):\n",
    "   1008                 pass\n",
    "   1009 \n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py in dispatch_one_batch(self, iterator)\n",
    "    833                 return False\n",
    "    834             else:\n",
    "--> 835                 self._dispatch(tasks)\n",
    "    836                 return True\n",
    "    837 \n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py in _dispatch(self, batch)\n",
    "    752         with self._lock:\n",
    "    753             job_idx = len(self._jobs)\n",
    "--> 754             job = self._backend.apply_async(batch, callback=cb)\n",
    "    755             # A job can complete so quickly than its callback is\n",
    "    756             # called before we get here, causing self._jobs to\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py in apply_async(self, func, callback)\n",
    "    207     def apply_async(self, func, callback=None):\n",
    "    208         \"\"\"Schedule a func to be run\"\"\"\n",
    "--> 209         result = ImmediateResult(func)\n",
    "    210         if callback:\n",
    "    211             callback(result)\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py in __init__(self, batch)\n",
    "    588         # Don't delay the application, to avoid keeping the input\n",
    "    589         # arguments in memory\n",
    "--> 590         self.results = batch()\n",
    "    591 \n",
    "    592     def get(self):\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py in __call__(self)\n",
    "    254         with parallel_backend(self._backend, n_jobs=self._n_jobs):\n",
    "    255             return [func(*args, **kwargs)\n",
    "--> 256                     for func, args, kwargs in self.items]\n",
    "    257 \n",
    "    258     def __len__(self):\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py in <listcomp>(.0)\n",
    "    254         with parallel_backend(self._backend, n_jobs=self._n_jobs):\n",
    "    255             return [func(*args, **kwargs)\n",
    "--> 256                     for func, args, kwargs in self.items]\n",
    "    257 \n",
    "    258     def __len__(self):\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\n",
    "    542     else:\n",
    "    543         fit_time = time.time() - start_time\n",
    "--> 544         test_scores = _score(estimator, X_test, y_test, scorer)\n",
    "    545         score_time = time.time() - start_time - fit_time\n",
    "    546         if return_train_score:\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator, X_test, y_test, scorer)\n",
    "    589         scores = scorer(estimator, X_test)\n",
    "    590     else:\n",
    "--> 591         scores = scorer(estimator, X_test, y_test)\n",
    "    592 \n",
    "    593     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py in __call__(self, estimator, *args, **kwargs)\n",
    "     87                                       *args, **kwargs)\n",
    "     88             else:\n",
    "---> 89                 score = scorer(estimator, *args, **kwargs)\n",
    "     90             scores[name] = score\n",
    "     91         return scores\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py in _passthrough_scorer(estimator, *args, **kwargs)\n",
    "    369 def _passthrough_scorer(estimator, *args, **kwargs):\n",
    "    370     \"\"\"Function that wraps estimator.score\"\"\"\n",
    "--> 371     return estimator.score(*args, **kwargs)\n",
    "    372 \n",
    "    373 \n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in <lambda>(*args, **kwargs)\n",
    "    114 \n",
    "    115         # lambda, but not partial, allows help() to work with update_wrapper\n",
    "--> 116         out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n",
    "    117         # update the docstring of the returned function\n",
    "    118         update_wrapper(out, self.fn)\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in score(self, X, y, sample_weight)\n",
    "    613         Xt = X\n",
    "    614         for _, name, transform in self._iter(with_final=False):\n",
    "--> 615             Xt = transform.transform(Xt)\n",
    "    616         score_params = {}\n",
    "    617         if sample_weight is not None:\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in transform(self, raw_documents, copy)\n",
    "   1896                    \"be removed in 0.24.\")\n",
    "   1897             warnings.warn(msg, FutureWarning)\n",
    "-> 1898         X = super().transform(raw_documents)\n",
    "   1899         return self._tfidf.transform(X, copy=False)\n",
    "   1900 \n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in transform(self, raw_documents)\n",
    "   1268 \n",
    "   1269         # use the same matrix-building strategy as fit_transform\n",
    "-> 1270         _, X = self._count_vocab(raw_documents, fixed_vocab=True)\n",
    "   1271         if self.binary:\n",
    "   1272             X.data.fill(1)\n",
    "\n",
    "~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in _count_vocab(self, raw_documents, fixed_vocab)\n",
    "   1133                     feature_idx = vocabulary[feature]\n",
    "   1134                     if feature_idx not in feature_counter:\n",
    "-> 1135                         feature_counter[feature_idx] = 1\n",
    "   1136                     else:\n",
    "   1137                         feature_counter[feature_idx] += 1\n",
    "\n",
    "KeyboardInterrupt: \n",
    "\n",
    "## In-33, pg 344\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# extract scores from grid_search\n",
    "scores = grid.cv_results_['mean_test_score'].reshape(-1, 3).T\n",
    "# visualize heat map\n",
    "heatmap = mglearn.tools.heatmap(\n",
    "    scores, xlabel=\"C\", ylabel=\"ngram_range\", cmap=\"viridis\", fmt=\"%.3f\",\n",
    "    xticklabels=param_grid['logisticregression__C'],\n",
    "    yticklabels=param_grid['tfidfvectorizer__ngram_range'])\n",
    "plt.colorbar(heatmap)\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f} min\".format((b-a)/60))\n",
    "## In-33, pg 344\n",
    "​\n",
    "a= time.time()\n",
    "​"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
