{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports for all practice\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# mlpscaler = StandardScaler()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "#import time\n",
    "#a= time.time()\n",
    "#b= time.time()\n",
    "#print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (506, 13)\n",
      "Scaled Data shape: (506, 13)\n",
      "per-feature minimum before scaling:\n",
      " [9.0600e-03 0.0000e+00 4.6000e-01 0.0000e+00 3.8500e-01 3.5610e+00\n",
      " 2.9000e+00 1.1296e+00 1.0000e+00 1.8700e+02 1.2600e+01 2.5200e+00\n",
      " 1.7300e+00]\n",
      "per-feature maximum before scaling:\n",
      " [ 67.9208  95.      27.74     1.       0.871    8.725  100.      12.1265\n",
      "  24.     711.      22.     396.9     37.97  ]\n",
      "per-feature minimum after scaling:\n",
      " [3.07969394e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 5.54743053e-03\n",
      " 0.00000000e+00]\n",
      "per-feature maximum after scaling:\n",
      " [0.76334238 0.95       1.         1.         1.         0.98946158\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Import and split the data\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(\"Data shape: {}\".format(boston.data.shape))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    boston.data, boston.target, random_state=69)\n",
    "\n",
    "## SCALE & split scaled data\n",
    "scaler.fit(boston.data)\n",
    "X_scaled = scaler.transform(boston.data)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(\n",
    "    X_scaled, boston.target, random_state=69)\n",
    "print(\"Scaled Data shape: {}\".format(X_scaled.shape))\n",
    "\n",
    "print(\"per-feature minimum before scaling:\\n {}\".format(X_train.min(axis=0)))\n",
    "print(\"per-feature maximum before scaling:\\n {}\".format(X_train.max(axis=0)))\n",
    "print(\"per-feature minimum after scaling:\\n {}\".format(\n",
    "X_train_scaled.min(axis=0)))\n",
    "print(\"per-feature maximum after scaling:\\n {}\".format(\n",
    "X_train_scaled.max(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.7520\n",
      "Test set score: 0.6794\n",
      "Run time: 0.0060\n"
     ]
    }
   ],
   "source": [
    "## ROW 14\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# DEFAULT parameters: Ridge Regression\n",
    "ridge=Ridge().fit(X_train, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(ridge.score(X_test, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.7224\n",
      "Test set score: 0.6886\n",
      "Run time: 0.0040\n"
     ]
    }
   ],
   "source": [
    "## ROW 15\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# CUSTOM parameters: Ridge Regression\n",
    "ridge=Ridge(alpha=100).fit(X_train, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(ridge.score(X_test, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.9802\n",
      "Test set score: 0.8261\n",
      "Run time: 0.3308\n"
     ]
    }
   ],
   "source": [
    "## ROW 16\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# DEFAULT parameters: Random Forest REGRESSOR\n",
    "forest = RandomForestRegressor(random_state=69).fit(X_train, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(forest.score(X_test, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.9827\n",
      "Test set score: 0.8291\n",
      "Run time: 33.1015\n"
     ]
    }
   ],
   "source": [
    "## ROW 17\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# CUSTOM parameters: Random Forest REGRESSOR\n",
    "forest_cust = RandomForestRegressor(n_estimators=10000, random_state=69).fit(X_train, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(forest_cust.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(forest_cust.score(X_test, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.9830\n",
      "Test set score: 0.8287\n",
      "Run time: 0.2688\n"
     ]
    }
   ],
   "source": [
    "## ROW 18\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# DEFAULT parameters: Gradient Boosting REGRESSOR\n",
    "gbrt = GradientBoostingRegressor(random_state=69).fit(X_train, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(gbrt.score(X_test, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.9790\n",
      "Test set score: 0.8238\n",
      "Run time: 0.1159\n"
     ]
    }
   ],
   "source": [
    "## ROW 19 - learning rate\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# CUSTOM parameters: Gradient Boosting REGRESSOR\n",
    "## parameters to play with are learning_rate OR max_depth\n",
    "gbrt_cust1 = GradientBoostingRegressor(learning_rate=0.08,random_state=69).fit(X_train, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(gbrt_cust1.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(gbrt_cust1.score(X_test, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.9978\n",
      "Test set score: 0.8483\n",
      "Run time: 0.1582\n"
     ]
    }
   ],
   "source": [
    "## ROW 19 - max depth\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# CUSTOM parameters: Gradient Boosting REGRESSOR\n",
    "## parameters to play with are learning_rate OR max_depth\n",
    "gbrt_cust2 = GradientBoostingRegressor(max_depth=5,random_state=69).fit(X_train, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(gbrt_cust2.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(gbrt_cust2.score(X_test, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.3570\n",
      "Test set score: 0.3853\n",
      "Run time: 0.0370\n"
     ]
    }
   ],
   "source": [
    "## ROW 20\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# DEFAULT parameters: SVM\n",
    "svr = SVR(gamma='auto').fit(X_train_scaled, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(svr.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(svr.score(X_test_scaled, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.9695\n",
      "Test set score: 0.8010\n",
      "Run time: 0.3968\n"
     ]
    }
   ],
   "source": [
    "## ROW 21\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# CUSTOM parameters: SVM\n",
    "svr = SVR(C=1000).fit(X_train_scaled, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(svr.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(svr.score(X_test_scaled, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.9354\n",
      "Test set score: 0.7731\n",
      "Run time: 12.2590\n"
     ]
    }
   ],
   "source": [
    "## ROW 22\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# DEFAULT parameters: Neural Networks\n",
    "## Results whithout max_iter were \n",
    "## with max_iter=1e9 Trainng set score: 0.9354, Test set score: 0.7731, Run time: 12.2590\n",
    "\n",
    "mlp = MLPRegressor(random_state=69, max_iter=1000000000).fit(X_train_scaled, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(mlp.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainng set score: 0.9195\n",
      "Test set score: 0.7386\n",
      "Run time: 5.7875\n"
     ]
    }
   ],
   "source": [
    "## ROW 23\n",
    "\n",
    "a= time.time()\n",
    "\n",
    "# CUSTOM parameters: Neural Networks\n",
    "## tried hidden_layer_sizes=[50,50] and 25,25 and had lower accuracy\n",
    "## tried alpha of 10 an 100, tried alpha .01, .001\n",
    "mlp_cust = MLPRegressor(alpha=0.5,hidden_layer_sizes=[10, 10], max_iter=1000000000, random_state=69).fit(X_train_scaled, y_train)\n",
    "print(\"Trainng set score: {:.4f}\".format(mlp_cust.score(X_train_scaled, y_train)))\n",
    "print(\"Test set score: {:.4f}\".format(mlp_cust.score(X_test_scaled, y_test)))\n",
    "\n",
    "b= time.time()\n",
    "print(\"Run time: {:.4f}\".format(b-a))\n",
    "\n",
    "## alpha=0.5,hidden_layer_sizes=[100, 100], Trainng set score: 0.9525, Test set score: 0.7611, Run time: 6.8971\n",
    "## alpha=0.01,hidden_layer_sizes=[100, 100], Trainng set score: 0.9552, Test set score: 0.7571, Run time: 7.3978\n",
    "## alpha=0.5,hidden_layer_sizes=[25, 25],Trainng set score: 0.9358, Test set score: 0.7522, Run time: 4.5764\n",
    "## alpha=0.5,hidden_layer_sizes=[50, 50], Trainng set score: 0.9366, Test set score: 0.7511, Run time: 4.2456"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
